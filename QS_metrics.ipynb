{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Quasi-Stationary Metrics from the filtered MedCyclone composite table\n",
    "Apply different stationarity definitions to the dataset and detect the most  slow-moving or transient cyclone tracks in time and space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load python packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# from scipy.io import savemat (if you want to save final table as .mat)\n",
    "from scipy.io import loadmat\n",
    "from scipy.stats import rankdata\n",
    "\n",
    "import QS_functions as fm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load df_crossers.mat\n",
    "data = loadmat('.../my_path/df_meditracks.mat')\n",
    "\n",
    "cols = ['id', 'lon', 'lat', 'year', 'month', 'day', 'time', 'hPa']\n",
    "df_crossers = pd.DataFrame({col: data[col].flatten() for col in cols})\n",
    "df_crossers['medi_tracks'] = (data['medi_tracks'].flatten() == 1)\n",
    "\n",
    "# retain only medi_tracks that are True\n",
    "df_crossers = df_crossers[df_crossers['medi_tracks']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full-Track Stationarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_quantiles_and_categories(values, name):\n",
    "    # compute quantile ranks (0 to 1)\n",
    "    ranks = rankdata(values, method='ordinal')\n",
    "    quantiles = np.round((ranks - 1) / (len(values) - 1), 3)\n",
    "\n",
    "    # assign categories: 0 = unclassified, 1 = low, 2 = medium, 3 = high\n",
    "    # quantiles can be changed to suit needs of user\n",
    "    categories = np.zeros_like(quantiles)\n",
    "    categories[quantiles <= 0.10] = 1\n",
    "    categories[(quantiles >= 0.45) & (quantiles <= 0.55)] = 2\n",
    "    categories[quantiles >= 0.90] = 3\n",
    "    categories[np.isnan(values)] = np.nan\n",
    "\n",
    "    return pd.DataFrame({\n",
    "        'id': df_crossers['id'].unique()[:len(values)],  # match IDs\n",
    "        f'{name}_v': np.round(values, 3),\n",
    "        f'{name}_q': quantiles,\n",
    "        f'{name}_c': categories\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Median Velocity \"FT_MED_VEL\"\n",
    "- based on median propagation speed of a cyclone over its whole lifetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate median propagation speed (per hour) for each cyclone\n",
    "# --------------------------------------------------------------\n",
    "# For each unique cyclone ID in the dataframe:\n",
    "#   - select its track points (lat/lon)\n",
    "#   - compute the distance between consecutive points (1-hour time steps)\n",
    "#   - store the median speed of each cyclone\n",
    "#\n",
    "# Cyclone categorisation (slow, average, fast) is based on quantiles\n",
    "# and is handled using a helper function to assign quantile ranks and categories.\n",
    "# Resulting values are added to the main dataframe.\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "list_med_vel = []\n",
    "\n",
    "for cyclone_id in df_crossers['id'].unique():\n",
    "    cyclone = df_crossers[df_crossers['id'] == cyclone_id].reset_index(drop=True)\n",
    "    if len(cyclone) < 2:\n",
    "        continue\n",
    "    dists = [\n",
    "        fm.haversine(cyclone.loc[t, 'lon'], cyclone.loc[t, 'lat'],\n",
    "                     cyclone.loc[t+1, 'lon'], cyclone.loc[t+1, 'lat'])\n",
    "        for t in range(len(cyclone) - 1)\n",
    "    ]\n",
    "    list_med_vel.append(np.median(dists))\n",
    "\n",
    "median_vel = np.array(list_med_vel)\n",
    "\n",
    "# Create DataFrame with quantiles and categories\n",
    "df_med_vel = assign_quantiles_and_categories(median_vel, 'FT_MED_VEL')\n",
    "\n",
    "# Merge with original data\n",
    "df_crossers = df_crossers.merge(df_med_vel, on='id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total Distance \"FT_TOT_DIST\" ('Path Stationarity' as in Aregger, 2021)\n",
    "- based on maximum distance that a cyclone can travel over its whole lifetime\n",
    "- calculated by summing up the distances between each observational timestep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate total distance for each cyclone\n",
    "# --------------------------------------------------------------\n",
    "# For each unique cyclone ID in the dataframe:\n",
    "#   - select its track points (lat/lon)\n",
    "#   - compute the distance between consecutive points (1-hour time steps)\n",
    "#   - store the median speed of each cyclone\n",
    "#\n",
    "# Cyclone categorisation (slow, average, fast) is based on quantiles\n",
    "# and is handled using a helper function to assign quantile ranks and categories.\n",
    "# Resulting values are added to the main dataframe.\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "list_tot_dist = []\n",
    "\n",
    "for cyclone_id in df_crossers['id'].unique():\n",
    "    cyclone = df_crossers[df_crossers['id'] == cyclone_id].reset_index(drop=True)\n",
    "    if len(cyclone) < 2:\n",
    "        continue\n",
    "    dists = [\n",
    "        fm.haversine(cyclone.loc[t, 'lon'], cyclone.loc[t, 'lat'],\n",
    "                     cyclone.loc[t+1, 'lon'], cyclone.loc[t+1, 'lat'])\n",
    "        for t in range(len(cyclone) - 1)\n",
    "    ]\n",
    "    list_tot_dist.append(np.sum(dists))\n",
    "\n",
    "tot_dist = np.array(list_tot_dist)\n",
    "\n",
    "# Create DataFrame with quantiles and categories\n",
    "df_tot_dist = assign_quantiles_and_categories(tot_dist, 'FT_TOT_DIST')\n",
    "\n",
    "# Merge with original data\n",
    "df_crossers = df_crossers.merge(df_tot_dist, on='id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Along Track Stationarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following three metrics all focus on distances covered in a 12-hr timescale.\n",
    "\n",
    "Users may change this window by altering the following variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorisation function, reusable for any dist DataFrame with ['id', 'lon', 'lat', 'dist_sum']\n",
    "def categorise_distances(df_dist, df_original, prefix):\n",
    "    # calculate percentiles (user may change these thresholds according to preference)\n",
    "    all_dist = df_dist['dist_sum'].values\n",
    "    perc_90 = np.percentile(all_dist, 90)\n",
    "    perc_45 = np.percentile(all_dist, 45)\n",
    "    perc_55 = np.percentile(all_dist, 55)\n",
    "    perc_10 = np.percentile(all_dist, 10)\n",
    "\n",
    "    # full values per ID with padding NaNs for trailing points\n",
    "    full_values = []\n",
    "    for ID_unique in np.unique(df_original.id.values):\n",
    "        vals = np.array([v for v in df_dist.loc[df_dist['id'] == ID_unique, 'dist_sum']])\n",
    "        vals = np.round(vals, 3)\n",
    "        vals_padded = np.append(vals, [np.nan]*window)  # pad for alignment\n",
    "        full_values.append(vals_padded)\n",
    "    full_values_concat = np.concatenate(full_values)\n",
    "\n",
    "    # calculate quantile ranks\n",
    "    ranks = rankdata(full_values_concat, method='ordinal', nan_policy='omit')\n",
    "    quantiles = np.where(np.isnan(full_values_concat), np.nan, (ranks - 1) / (len(full_values_concat[~np.isnan(full_values_concat)]) - 1))\n",
    "    quantiles = np.round(quantiles, 3)\n",
    "\n",
    "    # categorise based on quantiles\n",
    "    categories = np.zeros_like(quantiles)\n",
    "    categories[quantiles <= 0.1] = 1\n",
    "    categories[(quantiles >= 0.45) & (quantiles <= 0.55)] = 2\n",
    "    categories[quantiles >= 0.9] = 3\n",
    "    categories[np.isnan(quantiles)] = np.nan\n",
    "\n",
    "    # create DataFrame to join back to 'original' df_crossers\n",
    "    new_cols = pd.DataFrame({\n",
    "        f'{prefix}_v': full_values_concat,\n",
    "        f'{prefix}_q': quantiles,\n",
    "        f'{prefix}_c': categories    \n",
    "    })\n",
    "    new_cols.index = df_original.index  # align index\n",
    "\n",
    "    # return categorised dataframe and the three tracks filtered by percentile groups\n",
    "    return new_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12-hour Distance \"AT_12h_DIST\"\n",
    "- measures the total path distance a cyclone travels over 12 consecutive hourly steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_dist12h_df(df):\n",
    "    list_dist_12hrs = []\n",
    "    for id_val, group in df.groupby('id'):\n",
    "        lons = group['lon'].values\n",
    "        lats = group['lat'].values\n",
    "        for i in range(len(group) - window):\n",
    "            dist_sum = sum([fm.haversine(lons[j], lats[j], lons[j+1], lats[j+1]) for j in range(i, i+window)])\n",
    "            list_dist_12hrs.append([id_val, lons[i], lats[i], dist_sum])\n",
    "    return pd.DataFrame(list_dist_12hrs, columns=['id', 'lon', 'lat', 'dist_sum'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_12hr = calculate_dist12h_df(df_crossers)\n",
    "new_cols_12hr = categorise_distances(df_12hr, df_crossers, 'AT_12h_DIST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_crossers = pd.concat([df_crossers, new_cols_12hr], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Radial Distance \"AT_RAD_DIST\"\n",
    "- computes the sum of straight-line distances from a reference point to each of the next 12 hourly positions (like spokes of a wheel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_radial_df(df):\n",
    "    list_dist_rad = []\n",
    "    for id_val, group in df.groupby('id'):\n",
    "        lons = group['lon'].values\n",
    "        lats = group['lat'].values\n",
    "        for i in range(len(group) - window):\n",
    "            dist_sum = sum([fm.haversine(lons[i], lats[i], lons[j], lats[j]) for j in range(i+1, i+window+1)])\n",
    "            list_dist_rad.append([id_val, lons[i], lats[i], dist_sum])\n",
    "    return pd.DataFrame(list_dist_rad, columns=['id', 'lon', 'lat', 'dist_sum'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_radial = calculate_radial_df(df_crossers)\n",
    "new_cols_rad = categorise_distances(df_radial, df_crossers, 'AT_RAD_DIST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_crossers = pd.concat([df_crossers, new_cols_rad], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Circle Distance \"AT_CIRCLE_DIST\"\n",
    "- finds the maximum distance from a reference point to any of the next 12 positions, defining the radius of the smallest circle that contains them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_circle_df(df):\n",
    "    list_circle = []\n",
    "    for id_val, group in df.groupby('id'):\n",
    "        if len(group) <= window:\n",
    "            continue\n",
    "        for i in range(len(group) - window):\n",
    "            window_ = group.iloc[i:i + window+1]\n",
    "            center_lon, center_lat = window_.iloc[0][['lon', 'lat']]\n",
    "            lons = window_['lon'].values[1:]\n",
    "            lats = window_['lat'].values[1:]\n",
    "            distances = fm.haversine(center_lon, center_lat, lons, lats)\n",
    "            max_distance = distances.max()\n",
    "            list_circle.append([id_val, center_lon, center_lat, max_distance])\n",
    "    return pd.DataFrame(list_circle, columns=['id', 'lon', 'lat', 'dist_sum'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_circle = calculate_circle_df(df_crossers)\n",
    "new_cols_circle = categorise_distances(df_circle, df_crossers, 'AT_CIRCLE_DIST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_crossers = pd.concat([df_crossers, new_cols_circle], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save final QS Table as csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>time</th>\n",
       "      <th>hPa</th>\n",
       "      <th>medi_tracks</th>\n",
       "      <th>FT_MED_VEL_v</th>\n",
       "      <th>...</th>\n",
       "      <th>FT_TOT_DIST_c</th>\n",
       "      <th>AT_12h_DIST_v</th>\n",
       "      <th>AT_12h_DIST_q</th>\n",
       "      <th>AT_12h_DIST_c</th>\n",
       "      <th>AT_RAD_DIST_v</th>\n",
       "      <th>AT_RAD_DIST_q</th>\n",
       "      <th>AT_RAD_DIST_c</th>\n",
       "      <th>AT_CIRCLE_DIST_v</th>\n",
       "      <th>AT_CIRCLE_DIST_q</th>\n",
       "      <th>AT_CIRCLE_DIST_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0.960</td>\n",
       "      <td>40.700</td>\n",
       "      <td>1979</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>1016.93</td>\n",
       "      <td>True</td>\n",
       "      <td>31.008</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>293.162</td>\n",
       "      <td>0.585</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1554.441</td>\n",
       "      <td>0.513</td>\n",
       "      <td>2.0</td>\n",
       "      <td>259.569</td>\n",
       "      <td>0.573</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>1.080</td>\n",
       "      <td>40.761</td>\n",
       "      <td>1979</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>19</td>\n",
       "      <td>1016.93</td>\n",
       "      <td>True</td>\n",
       "      <td>31.008</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>313.308</td>\n",
       "      <td>0.628</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1710.421</td>\n",
       "      <td>0.566</td>\n",
       "      <td>0.0</td>\n",
       "      <td>279.078</td>\n",
       "      <td>0.616</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>1.300</td>\n",
       "      <td>40.746</td>\n",
       "      <td>1979</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>1016.64</td>\n",
       "      <td>True</td>\n",
       "      <td>31.008</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>321.903</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1779.949</td>\n",
       "      <td>0.588</td>\n",
       "      <td>0.0</td>\n",
       "      <td>288.992</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.624</td>\n",
       "      <td>40.699</td>\n",
       "      <td>1979</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>1016.35</td>\n",
       "      <td>True</td>\n",
       "      <td>31.008</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>319.393</td>\n",
       "      <td>0.640</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1752.835</td>\n",
       "      <td>0.580</td>\n",
       "      <td>0.0</td>\n",
       "      <td>290.526</td>\n",
       "      <td>0.639</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.986</td>\n",
       "      <td>40.693</td>\n",
       "      <td>1979</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>22</td>\n",
       "      <td>1015.86</td>\n",
       "      <td>True</td>\n",
       "      <td>31.008</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>313.970</td>\n",
       "      <td>0.629</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1687.237</td>\n",
       "      <td>0.558</td>\n",
       "      <td>0.0</td>\n",
       "      <td>287.221</td>\n",
       "      <td>0.633</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173785</th>\n",
       "      <td>3807</td>\n",
       "      <td>36.114</td>\n",
       "      <td>44.208</td>\n",
       "      <td>2020</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1015.46</td>\n",
       "      <td>True</td>\n",
       "      <td>10.430</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173786</th>\n",
       "      <td>3807</td>\n",
       "      <td>36.228</td>\n",
       "      <td>44.162</td>\n",
       "      <td>2020</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>1015.79</td>\n",
       "      <td>True</td>\n",
       "      <td>10.430</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173787</th>\n",
       "      <td>3807</td>\n",
       "      <td>36.323</td>\n",
       "      <td>44.163</td>\n",
       "      <td>2020</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>1016.16</td>\n",
       "      <td>True</td>\n",
       "      <td>10.430</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173788</th>\n",
       "      <td>3807</td>\n",
       "      <td>36.414</td>\n",
       "      <td>44.197</td>\n",
       "      <td>2020</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>1016.56</td>\n",
       "      <td>True</td>\n",
       "      <td>10.430</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173789</th>\n",
       "      <td>3807</td>\n",
       "      <td>36.510</td>\n",
       "      <td>44.240</td>\n",
       "      <td>2020</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>1016.73</td>\n",
       "      <td>True</td>\n",
       "      <td>10.430</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>173790 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id     lon     lat  year  month  day  time      hPa  medi_tracks  \\\n",
       "0          4   0.960  40.700  1979      1    8    18  1016.93         True   \n",
       "1          4   1.080  40.761  1979      1    8    19  1016.93         True   \n",
       "2          4   1.300  40.746  1979      1    8    20  1016.64         True   \n",
       "3          4   1.624  40.699  1979      1    8    21  1016.35         True   \n",
       "4          4   1.986  40.693  1979      1    8    22  1015.86         True   \n",
       "...      ...     ...     ...   ...    ...  ...   ...      ...          ...   \n",
       "173785  3807  36.114  44.208  2020      9    8     2  1015.46         True   \n",
       "173786  3807  36.228  44.162  2020      9    8     3  1015.79         True   \n",
       "173787  3807  36.323  44.163  2020      9    8     4  1016.16         True   \n",
       "173788  3807  36.414  44.197  2020      9    8     5  1016.56         True   \n",
       "173789  3807  36.510  44.240  2020      9    8     6  1016.73         True   \n",
       "\n",
       "        FT_MED_VEL_v  ...  FT_TOT_DIST_c  AT_12h_DIST_v  AT_12h_DIST_q  \\\n",
       "0             31.008  ...            0.0        293.162          0.585   \n",
       "1             31.008  ...            0.0        313.308          0.628   \n",
       "2             31.008  ...            0.0        321.903          0.645   \n",
       "3             31.008  ...            0.0        319.393          0.640   \n",
       "4             31.008  ...            0.0        313.970          0.629   \n",
       "...              ...  ...            ...            ...            ...   \n",
       "173785        10.430  ...            0.0            NaN            NaN   \n",
       "173786        10.430  ...            0.0            NaN            NaN   \n",
       "173787        10.430  ...            0.0            NaN            NaN   \n",
       "173788        10.430  ...            0.0            NaN            NaN   \n",
       "173789        10.430  ...            0.0            NaN            NaN   \n",
       "\n",
       "        AT_12h_DIST_c  AT_RAD_DIST_v  AT_RAD_DIST_q  AT_RAD_DIST_c  \\\n",
       "0                 0.0       1554.441          0.513            2.0   \n",
       "1                 0.0       1710.421          0.566            0.0   \n",
       "2                 0.0       1779.949          0.588            0.0   \n",
       "3                 0.0       1752.835          0.580            0.0   \n",
       "4                 0.0       1687.237          0.558            0.0   \n",
       "...               ...            ...            ...            ...   \n",
       "173785            NaN            NaN            NaN            NaN   \n",
       "173786            NaN            NaN            NaN            NaN   \n",
       "173787            NaN            NaN            NaN            NaN   \n",
       "173788            NaN            NaN            NaN            NaN   \n",
       "173789            NaN            NaN            NaN            NaN   \n",
       "\n",
       "        AT_CIRCLE_DIST_v  AT_CIRCLE_DIST_q  AT_CIRCLE_DIST_c  \n",
       "0                259.569             0.573               0.0  \n",
       "1                279.078             0.616               0.0  \n",
       "2                288.992             0.636               0.0  \n",
       "3                290.526             0.639               0.0  \n",
       "4                287.221             0.633               0.0  \n",
       "...                  ...               ...               ...  \n",
       "173785               NaN               NaN               NaN  \n",
       "173786               NaN               NaN               NaN  \n",
       "173787               NaN               NaN               NaN  \n",
       "173788               NaN               NaN               NaN  \n",
       "173789               NaN               NaN               NaN  \n",
       "\n",
       "[173790 rows x 24 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_QS = df_crossers\n",
    "df_QS\n",
    "# df_QS.to_csv('/.../my_path/df_QS.csv', index=False) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mamba-new",
   "language": "python",
   "name": "mamba-new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
